{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a7d5b2",
   "metadata": {},
   "source": [
    "# Week 11 Coding Homework – Event Studies & Placebo Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85de9f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.3)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [statsmodels]\u001b[0m [statsmodels]\n",
      "\u001b[1A\u001b[2KSuccessfully installed patsy-1.0.2 statsmodels-0.14.5\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# For reproducibility in ad-hoc experiments\n",
    "np.random.seed(0)\n",
    "\n",
    "num = 1000\n",
    "event_time = int(num / 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce80c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9268039244154727\n"
     ]
    }
   ],
   "source": [
    "num = 1000 \n",
    " \n",
    "event_time = int(num / 2) \n",
    " \n",
    "R_market = np.random.normal(0, 1, num) + np.arange(num) / num \n",
    " \n",
    "R_target = 2 + R_market + np.random.normal(0, 1, num) + (np.arange(num) == int(num / 2) + 1) * 2 \n",
    " \n",
    "results = sm.OLS(R_target[:event_time], sm.add_constant(R_market[:event_time])).fit() \n",
    " \n",
    "alpha, beta = results.params \n",
    " \n",
    "resid = R_target - results.predict(sm.add_constant(R_market)) \n",
    " \n",
    "print(resid[event_time + 1] / resid[:event_time].std(ddof = 2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94f29f",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "Which is closest to the probability that this t-test will be able to detect the event at event_time + 1 with the given code? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3753b35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5035)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_q1_once(num=1000):\n",
    "    event_time = int(num / 2)\n",
    "    \n",
    "    # Generate data\n",
    "    R_market = np.random.normal(0, 1, num) + np.arange(num) / num\n",
    "    R_target = (\n",
    "        2\n",
    "        + R_market\n",
    "        + np.random.normal(0, 1, num)\n",
    "        + (np.arange(num) == int(num / 2) + 1) * 2\n",
    "    )\n",
    "    \n",
    "    # Fit market model before event_time\n",
    "    results = sm.OLS(R_target[:event_time], sm.add_constant(R_market[:event_time])).fit()\n",
    "    \n",
    "    # Residuals over full horizon\n",
    "    resid = R_target - results.predict(sm.add_constant(R_market))\n",
    "    \n",
    "    # t-stat at event_time + 1\n",
    "    t_val = resid[event_time + 1] / resid[:event_time].std(ddof=2)\n",
    "    return t_val\n",
    "\n",
    "# Run many simulations\n",
    "np.random.seed(0)\n",
    "num_sims = 2000\n",
    "t_values = [simulate_q1_once(num) for _ in range(num_sims)]\n",
    "\n",
    "# Estimate power (probability of detection)\n",
    "power_estimate = np.mean(np.abs(t_values) > 1.96)\n",
    "power_estimate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b9b40",
   "metadata": {},
   "source": [
    "## Question 2 \n",
    "\n",
    "Use the same code but put np.random.seed(0) at the beginning of each loop to ensure that you are performing placebo tests on a fixed dataset. Perform a placebo test by setting the fictitious event_time to all possible times, while leaving the event in R_target at just the 1 time. The placebo test trains itself on the data leading up to the fictitious event. About what fraction of placebo tests seem to detect an event at the fictitious event time? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6a14ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04795918367346939)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate one fixed dataset\n",
    "np.random.seed(0)\n",
    "R_market = np.random.normal(0, 1, num) + np.arange(num) / num\n",
    "R_target = (\n",
    "    2\n",
    "    + R_market\n",
    "    + np.random.normal(0, 1, num)\n",
    "    + (np.arange(num) == event_time + 1) * 2  # real event at event_time+1\n",
    ")\n",
    "\n",
    "# Perform placebo tests for all plausible fictitious event times\n",
    "placebo_results = []\n",
    "\n",
    "# Avoid too-small samples at the beginning and end\n",
    "for fict_event in range(10, num - 10):\n",
    "    # Train on data BEFORE the fictitious event\n",
    "    R_m_train = R_market[:fict_event]\n",
    "    R_t_train = R_target[:fict_event]\n",
    "    \n",
    "    model = sm.OLS(R_t_train, sm.add_constant(R_m_train)).fit()\n",
    "    \n",
    "    # Residuals on full series\n",
    "    resid = R_target - model.predict(sm.add_constant(R_market))\n",
    "    \n",
    "    # t-stat at fictitious event\n",
    "    t_stat = resid[fict_event] / resid[:fict_event].std(ddof=2)\n",
    "    \n",
    "    placebo_results.append(np.abs(t_stat) > 1.96)\n",
    "\n",
    "fraction_placebo_detect = np.mean(placebo_results)\n",
    "fraction_placebo_detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1292e8",
   "metadata": {},
   "source": [
    "## Question 3 \n",
    "\n",
    "Do the same placebo test, but this time only run the test 20 times before and twenty times after the actual event. On average (over many runs of the code), what fraction of the 40 placebo tests get a higher t-value than the actual event? This time, adjust np.random.seed() to represent a different dataset when needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616bae1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.14575000000000002)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simulate_q3_once(num=1000, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    event_time = int(num / 2)\n",
    "    \n",
    "    # Generate dataset\n",
    "    R_market = np.random.normal(0, 1, num) + np.arange(num) / num\n",
    "    R_target = (\n",
    "        2\n",
    "        + R_market\n",
    "        + np.random.normal(0, 1, num)\n",
    "        + (np.arange(num) == event_time + 1) * 2  # real event\n",
    "    )\n",
    "    \n",
    "    # Fit on data before the true event_time (as in Q1)\n",
    "    results = sm.OLS(R_target[:event_time], sm.add_constant(R_market[:event_time])).fit()\n",
    "    resid = R_target - results.predict(sm.add_constant(R_market))\n",
    "    \n",
    "    # True event t-stat\n",
    "    t_true = resid[event_time + 1] / resid[:event_time].std(ddof=2)\n",
    "    \n",
    "    # Placebo events: 20 before and 20 after the true event\n",
    "    placebo_ts = []\n",
    "    for offset in range(-20, 0):\n",
    "        fict_event = event_time + 1 + offset\n",
    "        t_val = resid[fict_event] / resid[:fict_event].std(ddof=2)\n",
    "        placebo_ts.append(t_val)\n",
    "    for offset in range(1, 21):\n",
    "        fict_event = event_time + 1 + offset\n",
    "        t_val = resid[fict_event] / resid[:fict_event].std(ddof=2)\n",
    "        placebo_ts.append(t_val)\n",
    "    \n",
    "    placebo_ts = np.array(placebo_ts)\n",
    "    frac_larger = np.mean(np.abs(placebo_ts) > np.abs(t_true))\n",
    "    return frac_larger\n",
    "\n",
    "# Run many simulations with different seeds\n",
    "num_runs = 300\n",
    "fractions = [simulate_q3_once(num=num, seed=seed) for seed in range(num_runs)]\n",
    "np.mean(fractions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c37388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_error(corr_const, num): \n",
    " \n",
    " \n",
    "  sigma = 5 * 1 / np.sqrt((1 - corr_const)**2 / (1 - corr_const**2)) \n",
    " \n",
    " \n",
    "  err = list() \n",
    " \n",
    " \n",
    "  prev = np.random.normal(0, sigma) \n",
    " \n",
    " \n",
    "  for n in range(num): \n",
    " \n",
    " \n",
    "    prev = corr_const * prev + (1 - corr_const) * np.random.normal(0, sigma) \n",
    " \n",
    " \n",
    "    err.append(prev) \n",
    " \n",
    " \n",
    "  return np.array(err) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f52f56e",
   "metadata": {},
   "source": [
    "## Question 4 \n",
    "\n",
    "Do the same thing as in question 2, but this time use make_error with corr_const = 0.9 to generate the error for R_target instead of np.random.normal. Consider before attempting this: Would you expect this kind of dataset, where errors are not independent, to result in more or fewer false positives in the placebo tests? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46aea354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04081632653061224)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_error(corr_const, num):\n",
    "    sigma = 5 * 1 / np.sqrt((1 - corr_const)**2 / (1 - corr_const**2))\n",
    "    err = []\n",
    "    prev = np.random.normal(0, sigma)\n",
    "    for n in range(num):\n",
    "        prev = corr_const * prev + (1 - corr_const) * np.random.normal(0, sigma)\n",
    "        err.append(prev)\n",
    "    return np.array(err)\n",
    "\n",
    "# Generate one fixed dataset with autocorrelated errors\n",
    "np.random.seed(0)\n",
    "R_market = np.random.normal(0, 1, num) + np.arange(num) / num\n",
    "err = make_error(0.9, num)\n",
    "\n",
    "R_target_auto = (\n",
    "    2\n",
    "    + R_market\n",
    "    + err\n",
    "    + (np.arange(num) == event_time + 1) * 2  # real event at event_time+1\n",
    ")\n",
    "\n",
    "# Placebo tests over many fictitious event times\n",
    "placebo_results_auto = []\n",
    "\n",
    "for fict_event in range(10, num - 10):\n",
    "    # Train on data before fictitious event\n",
    "    R_m_train = R_market[:fict_event]\n",
    "    R_t_train = R_target_auto[:fict_event]\n",
    "    \n",
    "    model = sm.OLS(R_t_train, sm.add_constant(R_m_train)).fit()\n",
    "    \n",
    "    resid = R_target_auto - model.predict(sm.add_constant(R_market))\n",
    "    \n",
    "    t_stat = resid[fict_event] / resid[:fict_event].std(ddof=2)\n",
    "    placebo_results_auto.append(np.abs(t_stat) > 1.96)\n",
    "\n",
    "fraction_placebo_detect_auto = np.mean(placebo_results_auto)\n",
    "fraction_placebo_detect_auto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25073c08",
   "metadata": {},
   "source": [
    "## REFLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b0876",
   "metadata": {},
   "source": [
    "1. Construct a dataset for an event study where the value, derivative, and second derivative of a trend all change discontinuously (suddenly) after an event.\n",
    "Build a model that tries to decide whether the event is real (has a nonzero effect) using:\n",
    "(a) only the value,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8325c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 3.715e+04\n",
      "Date:                Sat, 22 Nov 2025   Prob (F-statistic):          9.94e-270\n",
      "Time:                        22:49:33   Log-Likelihood:                -860.88\n",
      "No. Observations:                 200   AIC:                             1730.\n",
      "Df Residuals:                     196   BIC:                             1743.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         44.5678      3.992     11.164      0.000      36.695      52.441\n",
      "x1           228.1174      5.119     44.567      0.000     218.023     238.212\n",
      "x2            -2.8714      0.095    -30.076      0.000      -3.060      -2.683\n",
      "x3             0.0411      0.000     95.674      0.000       0.040       0.042\n",
      "==============================================================================\n",
      "Omnibus:                       22.282   Durbin-Watson:                   0.025\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               26.093\n",
      "Skew:                          -0.843   Prob(JB):                     2.16e-06\n",
      "Kurtosis:                       3.535   Cond. No.                     7.50e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.5e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Event coefficient (beta_event): 228.11741972056552\n",
      "p-value for event effect: 1.6033894029514882e-104\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Set up time and event\n",
    "T = 200\n",
    "t = np.arange(T)\n",
    "event_time = 100\n",
    "post = (t > event_time).astype(int)\n",
    "\n",
    "# Construct Y with different level, slope, and curvature after the event\n",
    "# Pre-event: mild quadratic\n",
    "# Post-event: bigger intercept, steeper slope, more curvature\n",
    "Y = np.where(\n",
    "    t <= event_time,\n",
    "    0.01 * t**2 + 0.1 * t,                       # pre-event trend\n",
    "    (0.03 * t**2 + 0.6 * t + 10),                # post-event trend: level, slope, curvature all changed\n",
    ")\n",
    "\n",
    "# Add noise\n",
    "Y = Y + np.random.normal(0, 1, size=T)\n",
    "\n",
    "# Model using ONLY the value (no explicit derivatives),\n",
    "# but allowing for a general trend via t and t^2\n",
    "X = np.column_stack([post, t, t**2])   # event indicator + time + time^2\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# The key question: is the event \"real\"?\n",
    "# That is, is the coefficient on `post` (the event dummy) significantly nonzero?\n",
    "beta_event = model.params[1]\n",
    "pval_event = model.pvalues[1]\n",
    "print(\"Event coefficient (beta_event):\", beta_event)\n",
    "print(\"p-value for event effect:\", pval_event)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b60c96",
   "metadata": {},
   "source": [
    "(b) the value, derivative, and second derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361458b5",
   "metadata": {},
   "source": [
    "For part (b), I added the first and second differences so the model could look at how the value, slope, and curvature all changed after the event. This version did a better job because it did not just say something happened, it showed what changed. It picked up the jump in the value, the shift in the trend, and the change in curvature separately. Here, “better” means it detected the event more clearly and gave a more useful picture of what actually changed instead of blending everything into one effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b79b1",
   "metadata": {},
   "source": [
    "## Which of these models is better at detecting and/or quantifying the impact of the event?  (What might \"better\" mean here?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7861705",
   "metadata": {},
   "source": [
    "The model that uses the value, the first difference, and the second difference is better because it captures more of the ways the event affects the data. Instead of mixing everything into one shift, it shows whether the event changed the level, the slope, or the curvature. In this context, “better” means the model is more sensitive to the event, offers clearer evidence that something changed, and gives a more detailed picture of what the impact actually looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665efccc",
   "metadata": {},
   "source": [
    "2. Construct a dataset in which there are three groups whose values each increase discontinuously (suddenly) by the same amount at a shared event; they change in parallel\n",
    "over time, but they have different starting values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32bb5d",
   "metadata": {},
   "source": [
    "For this part, I set up a simple panel-style dataset with three groups observed over time. Each group followed the same upward trend over time, but I gave them different starting values by adding a different constant to each group so one started low, one in the middle, and one higher. At a chosen event time, I added the same fixed jump to all three groups’ values so they each increased suddenly by the same amount. This way the groups stayed in parallel before and after the event, kept their baseline differences, and shared a common discrete jump at the event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017108ce",
   "metadata": {},
   "source": [
    "Create a model that combines group fixed effects with an event study, as suggested in the online reading.\n",
    "Explain what you did, how the model works, and how it accounts for both baseline differences and the common event effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a84f83",
   "metadata": {},
   "source": [
    "I fit a regression that included group fixed effects along with a post-event indicator. The group fixed effects captured the baseline differences between the three groups, since each group started at a different level but followed the same trend. The post-event indicator captured the sudden jump that all groups experienced at the same time. By separating these two pieces, the model explained who starts higher through the fixed effects and explained the shared event impact through the post variable. This let the model account for both the different starting points across groups and the common shift caused by the event."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
